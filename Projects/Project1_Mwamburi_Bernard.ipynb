{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ea54824",
   "metadata": {},
   "source": [
    "#### 1. Load the dataset, airfoil_self_noise.DAT, into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "534e808b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>attack_angle</th>\n",
       "      <th>chord_length</th>\n",
       "      <th>free_stream_velocity</th>\n",
       "      <th>suction_side_disp</th>\n",
       "      <th>scaled_sound_pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>126.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frequency  attack_angle  chord_length  free_stream_velocity  \\\n",
       "0        800           0.0        0.3048                  71.3   \n",
       "1       1000           0.0        0.3048                  71.3   \n",
       "2       1250           0.0        0.3048                  71.3   \n",
       "3       1600           0.0        0.3048                  71.3   \n",
       "4       2000           0.0        0.3048                  71.3   \n",
       "\n",
       "   suction_side_disp  scaled_sound_pressure  \n",
       "0           0.002663                126.201  \n",
       "1           0.002663                125.201  \n",
       "2           0.002663                125.951  \n",
       "3           0.002663                127.591  \n",
       "4           0.002663                127.461  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['frequency', 'attack_angle', 'chord_length', 'free_stream_velocity',\n",
    "           'suction_side_disp', 'scaled_sound_pressure']\n",
    "df = pd.read_csv('airfoil_self_noise.dat', sep='\\t', header=None)\n",
    "df.columns = columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae4485a",
   "metadata": {},
   "source": [
    "#### 2. Clean the data and check missing values for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ac0efd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frequency                0\n",
       "attack_angle             0\n",
       "chord_length             0\n",
       "free_stream_velocity     0\n",
       "suction_side_disp        0\n",
       "scaled_sound_pressure    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159ce197",
   "metadata": {},
   "source": [
    "#### 3.a Split the data into 80% of training and 20% of the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b94d3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('scaled_sound_pressure', axis=1)\n",
    "y = df.scaled_sound_pressure\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1f356c",
   "metadata": {},
   "source": [
    "#### 3.b Build a simple linear regression to forecast \"Scaled sound pressure level\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f64556d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean square error is 25.0018\n",
      "The root mean square error is 5.0002\n",
      "The mean absolute error is 3.8455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print(f'''\n",
    "The mean square error is {np.round(mean_squared_error(y_test,pred),4)}\n",
    "The root mean square error is {np.round(mean_squared_error(y_test,pred, squared = False),4)}\n",
    "The mean absolute error is {np.round(mean_absolute_error(y_test,pred),4)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98194af",
   "metadata": {},
   "source": [
    "#### 4. Preprocess the data using the normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68eed1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer = Normalizer()\n",
    "X_train= normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4ef811",
   "metadata": {},
   "source": [
    "#### 5. Build a deep learning regression model to forecast \"Scaled sound pressure level\" using all other features and TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c63f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccd4c4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9e5db54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Sequential model with  layers\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(20, activation='relu'),\n",
    "        layers.Dense(1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06451124",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec719532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 1s 18ms/step - loss: 11019.3076 - val_loss: 7681.1484\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5554.8237 - val_loss: 3574.3879\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2602.1719 - val_loss: 1674.9503\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1233.2937 - val_loss: 795.7920\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 597.2927 - val_loss: 390.3638\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 302.3779 - val_loss: 204.0824\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 165.7404 - val_loss: 118.5876\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 102.2762 - val_loss: 79.6847\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 72.8303 - val_loss: 62.0338\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 59.1297 - val_loss: 54.2481\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 52.8043 - val_loss: 50.8004\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 49.8206 - val_loss: 49.3798\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 48.4522 - val_loss: 48.8252\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.8282 - val_loss: 48.6482\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.5398 - val_loss: 48.6056\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.3892 - val_loss: 48.6208\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.3342 - val_loss: 48.6546\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2974 - val_loss: 48.6924\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2896 - val_loss: 48.7080\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2821 - val_loss: 48.7399\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2799 - val_loss: 48.7543\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2747 - val_loss: 48.7589\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2770 - val_loss: 48.7717\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2814 - val_loss: 48.7787\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2817 - val_loss: 48.7726\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2788 - val_loss: 48.7709\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2770 - val_loss: 48.7699\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2765 - val_loss: 48.7688\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2779 - val_loss: 48.7797\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2785 - val_loss: 48.7831\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2768 - val_loss: 48.7635\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2846 - val_loss: 48.7628\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2821 - val_loss: 48.7560\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47.2751 - val_loss: 48.7605\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2712 - val_loss: 48.7580\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2761 - val_loss: 48.7545\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2791 - val_loss: 48.7561\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2715 - val_loss: 48.7664\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2810 - val_loss: 48.7741\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2761 - val_loss: 48.7619\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2749 - val_loss: 48.7506\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2747 - val_loss: 48.7575\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2757 - val_loss: 48.7632\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2798 - val_loss: 48.7702\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2787 - val_loss: 48.7603\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2732 - val_loss: 48.7530\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2838 - val_loss: 48.7531\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2835 - val_loss: 48.7526\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2805 - val_loss: 48.7671\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2736 - val_loss: 48.7756\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2834 - val_loss: 48.7699\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2766 - val_loss: 48.7684\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2727 - val_loss: 48.7597\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2810 - val_loss: 48.7552\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2802 - val_loss: 48.7570\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47.2795 - val_loss: 48.7581\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2815 - val_loss: 48.7521\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2799 - val_loss: 48.7465\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2801 - val_loss: 48.7576\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2733 - val_loss: 48.7631\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2757 - val_loss: 48.7718\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2814 - val_loss: 48.7672\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2785 - val_loss: 48.7622\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2739 - val_loss: 48.7629\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2762 - val_loss: 48.7666\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2846 - val_loss: 48.7609\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2740 - val_loss: 48.7568\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2727 - val_loss: 48.7635\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2860 - val_loss: 48.7629\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2845 - val_loss: 48.7604\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2855 - val_loss: 48.7682\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2859 - val_loss: 48.7758\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2724 - val_loss: 48.7563\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2780 - val_loss: 48.7546\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2842 - val_loss: 48.7504\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2799 - val_loss: 48.7515\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2718 - val_loss: 48.7510\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.2754 - val_loss: 48.7556\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2755 - val_loss: 48.7573\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2776 - val_loss: 48.7638\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 6ms/step - loss: 47.2863 - val_loss: 48.7618\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47.2791 - val_loss: 48.7584\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47.2814 - val_loss: 48.7683\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2760 - val_loss: 48.7648\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47.2793 - val_loss: 48.7768\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47.2794 - val_loss: 48.7702\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47.2786 - val_loss: 48.7740\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2761 - val_loss: 48.7676\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47.2789 - val_loss: 48.7671\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47.2721 - val_loss: 48.7674\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47.2789 - val_loss: 48.7644\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47.2780 - val_loss: 48.7583\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 47.2732 - val_loss: 48.7545\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47.2791 - val_loss: 48.7579\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47.2757 - val_loss: 48.7543\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47.2769 - val_loss: 48.7511\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47.2875 - val_loss: 48.7393\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47.2843 - val_loss: 48.7566\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47.2781 - val_loss: 48.7562\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47.2727 - val_loss: 48.7497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2648f682350>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "model.fit(x=X_train,y=y_train,batch_size=64,epochs=100,\n",
    "          validation_data=(X_test,y_test)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66bd340a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c9a96de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean square error is 48.7497\n",
      "The root mean square error is 6.9821\n",
      "The mean absolute error is 5.8242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "The mean square error is {np.round(mean_squared_error(y_test,y_pred),4)}\n",
    "The root mean square error is {np.round(mean_squared_error(y_test,y_pred, squared = False),4)}\n",
    "The mean absolute error is {np.round(mean_absolute_error(y_test,y_pred),4)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7b292d",
   "metadata": {},
   "source": [
    "#### 6. Can you improve the model performance of question 5 by adjusting the number of neurons or the optimization algorithm?\n",
    "Yes the model can be improved by adjusting the number of neurons or the optimization algorithm. In the above model the optimization algorithm SGD (Gradient Descent) improved model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a460ad4",
   "metadata": {},
   "source": [
    "#### 7. Build a deep learning regression model to forecast \"Scaled sound pressure level\" using all other features and PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c679b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8e1047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train.astype(np.float32))\n",
    "y_train = torch.tensor(y_train.values.astype(np.float32).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4bb7cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1202, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f969ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "input_size = X_train.shape[1]\n",
    "output_size = y_train.shape[1]\n",
    "#specify the number of neuron for the first hidden layer\n",
    "hidden_size = 15\n",
    "print(input_size)\n",
    "print(output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab1f1265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the child module class derivated from parent class of torch.nn.Module)\n",
    "class LinearRegressionModel(torch.nn.Module):\n",
    "    #define the constructor\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(input_size, hidden_size)  \n",
    "        self.predict = torch.nn.Linear(hidden_size, output_size)  \n",
    "    #overife the forward function in this child class\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))     \n",
    "        y_pred = self.predict(x)            \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53525232",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LinearRegressionModel(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f57c511",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae8c3901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MRT\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11070). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\c10\\cuda\\CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1216ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss:15628.7451\n",
      "epoch 1, loss:15556.9854\n",
      "epoch 2, loss:15486.8320\n",
      "epoch 3, loss:15411.6035\n",
      "epoch 4, loss:15327.2979\n",
      "epoch 5, loss:15232.6738\n",
      "epoch 6, loss:15126.6387\n",
      "epoch 7, loss:15007.9453\n",
      "epoch 8, loss:14875.5986\n",
      "epoch 9, loss:14728.8252\n",
      "epoch 10, loss:14567.0254\n",
      "epoch 11, loss:14389.8398\n",
      "epoch 12, loss:14196.9746\n",
      "epoch 13, loss:13988.1064\n",
      "epoch 14, loss:13762.9238\n",
      "epoch 15, loss:13521.1436\n",
      "epoch 16, loss:13262.5654\n",
      "epoch 17, loss:12987.0898\n",
      "epoch 18, loss:12694.7422\n",
      "epoch 19, loss:12385.6543\n",
      "epoch 20, loss:12060.0762\n",
      "epoch 21, loss:11718.3740\n",
      "epoch 22, loss:11361.0195\n",
      "epoch 23, loss:10988.6133\n",
      "epoch 24, loss:10601.8682\n",
      "epoch 25, loss:10201.6250\n",
      "epoch 26, loss:9788.8535\n",
      "epoch 27, loss:9364.6494\n",
      "epoch 28, loss:8930.2471\n",
      "epoch 29, loss:8487.0098\n",
      "epoch 30, loss:8036.4326\n",
      "epoch 31, loss:7580.1445\n",
      "epoch 32, loss:7119.8970\n",
      "epoch 33, loss:6657.5649\n",
      "epoch 34, loss:6195.1382\n",
      "epoch 35, loss:5734.7090\n",
      "epoch 36, loss:5278.4590\n",
      "epoch 37, loss:4828.6499\n",
      "epoch 38, loss:4387.5962\n",
      "epoch 39, loss:3957.6484\n",
      "epoch 40, loss:3541.1636\n",
      "epoch 41, loss:3140.4783\n",
      "epoch 42, loss:2757.8713\n",
      "epoch 43, loss:2395.5256\n",
      "epoch 44, loss:2055.4839\n",
      "epoch 45, loss:1739.6049\n",
      "epoch 46, loss:1449.5098\n",
      "epoch 47, loss:1186.5328\n",
      "epoch 48, loss:951.6687\n",
      "epoch 49, loss:745.5193\n",
      "epoch 50, loss:568.2529\n",
      "epoch 51, loss:419.5633\n",
      "epoch 52, loss:298.6462\n",
      "epoch 53, loss:204.1901\n",
      "epoch 54, loss:134.3874\n",
      "epoch 55, loss:86.9708\n",
      "epoch 56, loss:59.2728\n",
      "epoch 57, loss:48.3120\n",
      "epoch 58, loss:50.9019\n",
      "epoch 59, loss:63.7751\n",
      "epoch 60, loss:83.7172\n",
      "epoch 61, loss:107.6989\n",
      "epoch 62, loss:132.9954\n",
      "epoch 63, loss:157.2838\n",
      "epoch 64, loss:178.7120\n",
      "epoch 65, loss:195.9329\n",
      "epoch 66, loss:208.1039\n",
      "epoch 67, loss:214.8564\n",
      "epoch 68, loss:216.2397\n",
      "epoch 69, loss:212.6449\n",
      "epoch 70, loss:204.7221\n",
      "epoch 71, loss:193.2935\n",
      "epoch 72, loss:179.2697\n",
      "epoch 73, loss:163.5786\n",
      "epoch 74, loss:147.1039\n",
      "epoch 75, loss:130.6386\n",
      "epoch 76, loss:114.8538\n",
      "epoch 77, loss:100.2809\n",
      "epoch 78, loss:87.3044\n",
      "epoch 79, loss:76.1669\n",
      "epoch 80, loss:66.9802\n",
      "epoch 81, loss:59.7425\n",
      "epoch 82, loss:54.3589\n",
      "epoch 83, loss:50.6628\n",
      "epoch 84, loss:48.4377\n",
      "epoch 85, loss:47.4372\n",
      "epoch 86, loss:47.4035\n",
      "epoch 87, loss:48.0822\n",
      "epoch 88, loss:49.2347\n",
      "epoch 89, loss:50.6472\n",
      "epoch 90, loss:52.1370\n",
      "epoch 91, loss:53.5560\n",
      "epoch 92, loss:54.7914\n",
      "epoch 93, loss:55.7653\n",
      "epoch 94, loss:56.4318\n",
      "epoch 95, loss:56.7737\n",
      "epoch 96, loss:56.7976\n",
      "epoch 97, loss:56.5296\n",
      "epoch 98, loss:56.0098\n",
      "epoch 99, loss:55.2880\n"
     ]
    }
   ],
   "source": [
    "#fix the random seeds for troch and np\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(0)\n",
    "\n",
    "#set the number of epochs\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    #forward pass\n",
    "    y_pred = model2(X_train.requires_grad_())\n",
    "\n",
    "    #calculate the loss\n",
    "    loss= l(y_pred, y_train)\n",
    "    #Set the gradients to be zero\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #backward pass: calculate gradients\n",
    "    loss.backward()\n",
    "\n",
    "    #update the weights\n",
    "    optimizer.step()\n",
    "  \n",
    "    print('epoch {0}, loss:{1:.4f}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54f11bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert numpy to tensor\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "#Stop tracking the gradient by calling detach since we don't use it anymore\n",
    "y_pred2 = model2(X_test).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7e36828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean square error is 59.3436\n",
      "The root mean square error is 7.7035\n",
      "The mean absolute error is 6.2655\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "The mean square error is {np.round(mean_squared_error(y_test,y_pred2),4)}\n",
    "The root mean square error is {np.round(mean_squared_error(y_test,y_pred2, squared = False),4)}\n",
    "The mean absolute error is {np.round(mean_absolute_error(y_test,y_pred2),4)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676d2729",
   "metadata": {},
   "source": [
    "#### 8. Can you improve the model performance of question 7 by adjusting the number of neurons or the optimization algorithm?\n",
    "Yes the model can be improved by changing the number of neurons or optimization algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
